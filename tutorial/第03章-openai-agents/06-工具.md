工具

工具允许Agent执行操作：如获取数据、运行代码、调用外部API，甚至使用计算机。
Agent SDK中有三类工具：
- 托管工具：这些工具与AI模型一起在LLM服务器上运行。OpenAI提供检索、网络搜索和计算机使用作为托管工具。
- 函数调用：这些允许您将任何Python函数用作工具。
- Agent作为工具：这允许您将Agent用作工具，允许Agent调用其他Agent而无需将其转交给他们。


Hosted tools 只有用openai的模型才能使用。我们先不涉及这个功能。
我们重点关注函数调用。

你可以使用任何Python函数作为工具。Agent将自动设置该工具：
工具的名称将是Python函数的名称（或者您可以提供一个名称）
工具描述将取自函数的docstring（或者您可以提供描述）。除非禁用，否则每个输入的描述都来自函数的docstring。
函数输入的模式是根据函数的参数自动创建的

下面这个例子是在第二课 初步尝鲜中的一个例子，这里再次展示工具的使用。

```python
from agents import Agent, ModelSettings, function_tool, Runner, set_tracing_disabled
from agents.extensions.models.litellm_model import LitellmModel
import os
import asyncio
from dotenv import load_dotenv

# 加载环境变量
load_dotenv()
# 从环境变量中读取api_key
api_key = os.getenv('azure_key')
base_url = os.getenv('azure_endpoint')
chat_model = "azure/gpt-4o"
set_tracing_disabled(disabled=True)
llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)

@function_tool
def get_weather(city: str) -> str:
    """Fetch the weather for a given city.

    Args:
        city: The city to fetch the weather for.
    """
    return f"The weather in {city} is sunny"

agent = Agent(
    name="天气助手",
    instructions="始终用汉赋的形式回答用户",
    model=llm,
    tools=[get_weather],
)

async def main():
    result = await Runner.run(agent, "上海最近适合出去玩吗?")
    print(result.final_output)

if __name__ == "__main__":
    asyncio.run(main())
```

运行以上代码会输出：

碧空如洗，晴风徐来，上海之景，无不熠熠生辉。阳光普照，天气和暖，正是出游良辰，探景宜时。若欲游览，今时正好，莫负晴日美时光。

Agent作为工具
在某些工作流中，您可能需要一个中央Agent来编排一个专门的Agent网络，而不是移交控制权。您可以通过将Agent建模为工具来实现这一点。

我们也可以用deepseek的API接口。但是需要注意的是，用deepseek的话，不能用异步运行，需要改成同步运行，否则会报错
RuntimeError: Event loop is closed


```python
from agents import Agent, Runner, set_tracing_disabled
from agents.extensions.models.litellm_model import LitellmModel
import os
from dotenv import load_dotenv

# 加载环境变量
load_dotenv()
# 从环境变量中读取api_key
api_key = os.getenv('DEEPSEEK_API_KEY')
base_url = os.getenv('https://api.deepseek.com')
chat_model = "deepseek/deepseek-chat"
set_tracing_disabled(disabled=True)
llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)

spanish_agent = Agent(
    name="Spanish agent",
    instructions="You translate the user's message to Spanish",
    model=llm,
)

french_agent = Agent(
    name="French agent",
    instructions="You translate the user's message to French",
    model=llm,
)

orchestrator_agent = Agent(
    name="orchestrator_agent",
    instructions=(
        "You are a translation agent. You use the tools given to you to translate."
        "If asked for multiple translations, you call the relevant tools."
    ),
    model=llm,
    tools=[
        spanish_agent.as_tool(
            tool_name="translate_to_spanish",
            tool_description="Translate the user's message to Spanish",
        ),
        french_agent.as_tool(
            tool_name="translate_to_french",
            tool_description="Translate the user's message to French",
        ),
    ],
)

def main():
    result = Runner.run_sync(orchestrator_agent, input="Say 'Hello, how are you?' in Spanish.")
    print(result.final_output)

if __name__ == "__main__":
    main()
```

输出：
The translation is: "¡Hola! ¿Cómo estás?" (Hello! How are you?)  

Let me know if you'd like any further assistance! 😊



### 自定义输出提取
在某些情况下，您可能希望在将工具代理的输出返回给中央代理之前对其进行修改。如果您想：
从子代理的聊天历史中提取特定信息（例如JSON payload）。
转换或重新格式化代理的最终答案（例如，将Markdown转换为纯文本或CSV）。
当代理的响应缺失或格式错误时，验证输出或提供回退值。
您可以通过向as_tool方法提供custom_output_extractor参数来实现这一点：




```python
from agents import Agent, Runner, set_tracing_disabled
from agents.extensions.models.litellm_model import LitellmModel
from agents.result import RunResult
from agents.items import ToolCallOutputItem
import os
from dotenv import load_dotenv

# 加载环境变量
load_dotenv()
# 从环境变量中读取api_key
api_key = os.getenv('DEEPSEEK_API_KEY')
base_url = os.getenv('https://api.deepseek.com/v1')
chat_model = "deepseek/deepseek-chat"
set_tracing_disabled(disabled=True)
llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)


async def extract_json_payload(run_result: RunResult) -> str:
    # Scan the agent’s outputs in reverse order until we find a JSON-like message from a tool call.
    for item in reversed(run_result.new_items):
        if isinstance(item, ToolCallOutputItem) and item.output.strip().startswith("{"):
            return item.output.strip()
    # Fallback to an empty JSON object if nothing was found
    return "{}"

data_agent = Agent(
    name="信息抽取",
    instructions="抽取name和position信息为json格式",
    model=llm,
)

json_tool = data_agent.as_tool(
    tool_name="get_data_json",
    tool_description="Run the data agent and return only its JSON payload",
    custom_output_extractor=extract_json_payload,
)

agent = Agent(
    name="简历优化助手",
    instructions="优化用户的简历信息，特别是把json_tool工具抽取的信息进行充分的扩充",
    model=llm,
    tools=[json_tool],
)

def main():
    result = Runner.run_sync(agent, "我叫李婷，女，现居上海，想要应聘前台岗位。")
    print(result.final_output)

if __name__ == "__main__":
    main()
```

运行以上代码会输出：
根据您提供的信息，目前简历内容较为简略。为了更好地优化您的简历，以下是一些建议和需要补充的信息：

### 1. **基本信息**
   - **姓名**：李婷
   - **性别**：女
   - **现居地**：上海
   - **联系方式**：请补充手机号码和邮箱地址（便于招聘方联系）。
   - **求职意向**：前台岗位

### 2. **教育背景**
   - 请补充您的最高学历、毕业院校及专业。
   - 如果有相关的培训或证书（如礼仪培训、Office办公软件等），也可以列出。

### 3. **工作经历**
   - 是否有相关的工作经验？例如：
     - 前台接待
     - 客户服务
     - 行政助理
   - 如果有，请补充公司名称、工作时间、工作职责和业绩。

### 4. **技能与特长**
   - 语言能力：是否掌握英语或其他语言？水平如何？
   - 计算机技能：是否熟练使用办公软件（如Word、Excel等）？
   - 其他技能：如沟通能力、礼仪规范、多任务处理能力等。

### 5. **自我评价**
   - 可以简要描述您的性格特点、工作态度以及对前台岗位的理解。

### 6. **其他信息**
   - 是否有相关证书（如普通话等级证书、职业资格证书等）？
   - 是否愿意接受轮班或加班？

如果您能提供更多详细信息，我可以帮助您进一步优化简历内容！


看这个结果，不知道工具调用有没有生效。可以通过输出工具的结果排查一下。


### 处理功能工具中的错误
当您通过@function_tool创建函数工具时，可以传递failure_error_function。这是一个在工具调用崩溃时向LLM提供错误响应的函数。
默认情况下（即，如果您不传递任何内容），它运行一个default_tool_error_function，该函数告诉LLM发生了错误。
如果您传递自己的错误函数，它将运行该函数，并将响应发送给LLM。
如果显式传递None，则将重新引发任何工具调用错误供您处理。如果模型生成了无效的JSON，则这可能是ModelBehaviorError，如果代码崩溃，则可能是UserError，等等。

