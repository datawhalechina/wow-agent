# 任务转交
任务转交功能允许一个智能体将任务委托给另一个智能体。这在各智能体专攻不同领域的场景中尤为实用。例如，客户支持应用可能配置了分别处理订单状态、退款、常见问题等专项任务的智能体。

对大模型而言，任务转交以工具形式呈现。若存在向名为Refund Agent智能体的转交，对应工具将被命名为transfer_to_refund_agent。

### 创建任务转交
所有智能体都具备handoffs参数，该参数可直接接收Agent，或接受用于定制转交行为的Handoff对象。

您可通过Agents SDK提供的handoff()函数创建转交。此函数支持指定目标智能体，并可选择性地配置覆盖参数和输入过滤器。

基础用法
以下是创建简单转交的方法：

```python
from agents import Agent, Runner, set_tracing_disabled
import asyncio
from agents.extensions.models.litellm_model import LitellmModel
import os
from dotenv import load_dotenv

# 加载环境变量
load_dotenv()
# 从环境变量中读取api_key
api_key = os.getenv('mistral_key')
base_url = 'https://api.mistral.ai/v1'
chat_model = "mistral/mistral-small-latest"
set_tracing_disabled(disabled=True)
llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)

history_tutor_agent = Agent(
    name="History Tutor",
    handoff_description="Specialist agent for historical questions",
    instructions="You provide assistance with historical queries. Explain important events and context clearly.",
    model=llm,
)

math_tutor_agent = Agent(
    name="Math Tutor",
    handoff_description="Specialist agent for math questions",
    instructions="You provide help with math problems. Explain your reasoning at each step and include examples",
    model=llm,
)

triage_agent = Agent(
    name="Triage Agent",
    instructions="You determine which agent to use based on the user's homework question",
    handoffs=[history_tutor_agent, math_tutor_agent],
    model=llm,
)

async def main():
    result = await Runner.run(triage_agent, "What is the capital of France?")
    print(result.final_output)
if __name__ == "__main__":
    asyncio.run(main())
```

运行代码后，会输出：
The capital of France is Paris.

除了像上面一样传入handoffs=[history_tutor_agent, math_tutor_agent]参数，也可通过Agents SDK提供的handoff()函数创建转交。此函数支持指定目标智能体，并可选择性地配置覆盖参数和输入过滤器。

### 通过handoff()函数定制转交
handoff()函数支持以下定制项：

agent：指定接收转交的目标智能体
tool_name_override：默认使用Handoff.default_tool_name()函数（解析结果为transfer_to_<agent_name>），可在此处覆盖
tool_description_override：覆盖Handoff.default_tool_description()提供的默认工具描述
on_handoff：转交触发时执行的回调函数，适用于在确认转交后立即启动数据获取等场景。该函数接收智能体上下文，并可选择性接收大模型生成的输入（输入数据类型由input_type参数控制）
input_type：指定转交预期的输入类型（可选）
input_filter：用于过滤后续智能体接收的输入（详见下文）



```python
from agents import Agent, Runner, handoff, RunContextWrapper, set_tracing_disabled
import asyncio
from agents.extensions.models.litellm_model import LitellmModel
import os
from dotenv import load_dotenv

# 加载环境变量
load_dotenv()
# 从环境变量中读取api_key
api_key = os.getenv('mistral_key')
base_url = 'https://api.mistral.ai/v1'
chat_model = "mistral/mistral-small-latest"
set_tracing_disabled(disabled=True)
llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)


def on_handoff(ctx: RunContextWrapper[None]):
    print("Handoff called")


history_tutor_agent = Agent(
    name="History Tutor",
    handoff_description="Specialist agent for historical questions",
    instructions="You provide assistance with historical queries. Explain important events and context clearly.",
    model=llm,
)

math_tutor_agent = Agent(
    name="Math Tutor",
    handoff_description="Specialist agent for math questions",
    instructions="You provide help with math problems. Explain your reasoning at each step and include examples",
    model=llm,
)


handoff_obj = handoff(
    agent=math_tutor_agent,
    on_handoff=on_handoff,
    tool_name_override="custom_handoff_tool",
    tool_description_override="Custom description",
)

triage_agent = Agent(
    name="Triage Agent",
    instructions="You determine which agent to use based on the user's homework question",
    handoffs=[history_tutor_agent, handoff_obj],
    model=llm,
)

async def main():
    result = await Runner.run(triage_agent, "What is the capital of France?")
    print(result.final_output)
if __name__ == "__main__":
    asyncio.run(main())
```

运行代码后，会输出：
The capital of France is Paris.


### 转交输入
某些场景下，您可能希望大模型在调用转交时提供特定数据。例如向"升级专员"转交任务时，可能需要附带转交原因以便记录。


```python
from agents import Agent, Runner, handoff, RunContextWrapper, set_tracing_disabled
import asyncio
from agents.extensions.models.litellm_model import LitellmModel
import os
from pydantic import BaseModel
from dotenv import load_dotenv

# 加载环境变量
load_dotenv()
# 从环境变量中读取api_key
api_key = os.getenv('mistral_key')
base_url = 'https://api.mistral.ai/v1'
chat_model = "mistral/mistral-small-latest"
set_tracing_disabled(disabled=True)
llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)


class EscalationData(BaseModel):
    reason: str

async def on_handoff(ctx: RunContextWrapper[None], input_data: EscalationData):
    print(f"Escalation agent called with reason: {input_data.reason}")


history_tutor_agent = Agent(
    name="History Tutor",
    handoff_description="Specialist agent for historical questions",
    instructions="You provide assistance with historical queries. Explain important events and context clearly.",
    model=llm,
)

math_tutor_agent = Agent(
    name="Math Tutor Escalation agent",
    handoff_description="Specialist agent for math questions",
    instructions="You provide help with math problems. Explain your reasoning at each step and include examples",
    model=llm,
)

handoff_obj = handoff(
    agent=math_tutor_agent,
    on_handoff=on_handoff,
    tool_name_override="custom_handoff_tool",
    tool_description_override="Custom description",
    input_type=EscalationData,
)

triage_agent = Agent(
    name="Triage Agent",
    instructions=(
        "你必须根据用户的问题类型，使用以下工具之一进行转接：\n"
        "- 如果是历史问题，转接给历史导师。\n"
        "- 如果是数学问题，使用 custom_handoff_tool 转接给数学导师。\n"
        "不要自己回答问题，必须转接！"
    ),
    handoffs=[history_tutor_agent, handoff_obj],
    model=llm,
)

async def main():
    result = await Runner.run(triage_agent, "如何解决鸡兔同笼问题?")
    print(result.final_output)
if __name__ == "__main__":
    asyncio.run(main())
```

输出：
Escalation agent called with reason: 用户询问数学问题，需要转接数学导师
鸡兔同笼问题可以通过设立方程来解决。假设鸡有x只，兔子有y只，头的总数为H，脚的总数为F。根据题意，可以列出以下两个方程：

1. 头的总数：x + y = H
2. 脚的总数：2x + 4y = F

接下来，我们可以通过解这个方程组来找到x和y的值。首先，我们可以从第一个方程中解出x：

x = H - y

然后，将x的表达式代入第二个方程：

2(H - y) + 4y = F

展开并简化这个方程：

2H - 2y + 4y = F
2H + 2y = F

接下来，解这个方程来找到y的值：

2y = F - 2H
y = (F - 2H) / 2

最后，将y的值代入x的表达式中，以找到x的值：

x = H - y
x = H - (F - 2H) / 2

这样，我们就得到了鸡和兔子的数量。


这里有一个问题，handoff的参数 input_data 如何传入？有待后续有机会解决。


发生转交时，新智能体将接管整个对话历史。如需修改此行为，可设置input_filter。输入过滤器是接收HandoffInputData现有输入的函数，必须返回新的HandoffInputData。

agents.extensions.handoff_filters中已实现若干通用模式（例如清除历史记录中的所有工具调用）：



```python
from agents import Agent, Runner, handoff, RunContextWrapper, set_tracing_disabled, function_tool
from agents.extensions import handoff_filters
import asyncio
from agents.extensions.models.litellm_model import LitellmModel
import os
from dotenv import load_dotenv

# 加载环境变量
load_dotenv()
# 从环境变量中读取api_key
api_key = os.getenv('mistral_key')
base_url = 'https://api.mistral.ai/v1'
chat_model = "mistral/mistral-small-latest"
set_tracing_disabled(disabled=True)
llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)


@function_tool
def get_weather(city: str) -> str:
    """Fetch the weather for a given city.

    Args:
        city: The city to fetch the weather for.
    """
    print("使用天气工具")
    return f"The weather in {city} is sunny"


history_tutor_agent = Agent(
    name="History Tutor",
    handoff_description="Specialist agent for historical questions",
    instructions="You provide assistance with historical queries. Explain important events and context clearly.",
    model=llm,
)

math_tutor_agent = Agent(
    name="Math Tutor",
    handoff_description="Specialist agent for math questions",
    instructions="You provide help with math problems. Explain your reasoning at each step and include examples",
    model=llm,
)


handoff_obj = handoff(
    agent=math_tutor_agent,
    input_filter=handoff_filters.remove_all_tools,
)

triage_agent = Agent(
    name="Triage Agent",
    instructions="You determine which agent to use based on the user's homework question, on sunny days, you can let the math_tutor_agent do history homework.",
    handoffs=[history_tutor_agent, handoff_obj],
    tools=[get_weather],
    model=llm,
)

async def main():
    result = await Runner.run(triage_agent, "What is the capital of France?")
    print(result.final_output)
if __name__ == "__main__":
    asyncio.run(main())
```

运行代码后，会输出：
The capital of France is Paris. Paris has been the capital since the foundation of the French kingdom in the 6th century. It has played a central role in the country's history, politics, culture, and economy. Some key historical events related to Paris include:       

1. **Franc Kingdom Establishment (6th century)**: Clovis I, the first Frankish king to unite all of the Frankish tribes under one ruler, made Paris his capital.

2. **French Revolution (1789-1799)**: Paris was the epicenter of the French Revolution, which led to the overthrow of the monarchy and the establishment of the First French Republic.

3. **Napoleonic Era (1804-1815)**: Napoleon Bonaparte made Paris the center of his empire, and the city saw significant changes and developments during his reign.

4. **World War II (1939-1945)**: Paris was occupied by Nazi Germany from 1940 to 1944. The city was liberated by the Allies in August 
1944, marking a significant turning point in the war.

5. **Modern Era**: Today, Paris is a global hub for art, fashion, gastronomy, and culture. It is home to iconic landmarks such as the 
Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum. The city continues to be a major political and economic center, hosting international organizations like UNESCO and the OECD.

可见这是让数学Agent去解答历史题了。因为调用了工具。天气晴朗的时候，可以让数学Agent去解答历史题。


### 推荐提示词
为确保大模型正确理解转交机制，建议在智能体中包含转交说明。agents.extensions.handoff_prompt.RECOMMENDED_PROMPT_PREFIX提供建议前缀模板，或调用agents.extensions.handoff_prompt.prompt_with_handoff_instructions自动为提示词添加推荐内容。

```python
from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX
print(RECOMMENDED_PROMPT_PREFIX)
```
输出了
# System context
You are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.

看起来，是openai为我们提供的一段系统提示词，把这段话给大模型后，大模型就能知道这里有一个转交的动作。

它的用法就是和我们自己的提示词拼接起来即可。如下：

```python
from agents import Agent
from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX

billing_agent = Agent(
    name="Billing agent",
    instructions=f"""{RECOMMENDED_PROMPT_PREFIX}
    <Fill in the rest of your prompt here>.""",
)
```

在我们自己的提示词前面拼接一个RECOMMENDED_PROMPT_PREFIX即可。




